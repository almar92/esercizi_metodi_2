\chapter{Funzioni analitiche, prolungamenti ed espansioni asintotiche}

\section{Spunti di teoria (Davide Bufalini, Alessandro Marcelli)}

\subsection{I numeri complessi (Alessandro Marcelli)}

I numeri complessi possono essere espressi come somma di una \textbf{pare reale} e di una \textbf{parte immaginaria}
\begin{align}
	z = x + iy \spacer x,y \in \R
\end{align}
Si definisce il \textbf{complesso coniugato} di un numero complesso come
\begin{align}
	\overline{z} = x-iy
\end{align}
Possiamo definire il suo \textbf{modulo} come
\begin{align}
	|z|^2 = z \cdot \overline{z} = x^2 + y^2
\end{align}
Utilizzando queste due definizioni si possono riscrivere le parti reale e immaginaria come
\begin{align}
	x = \frac{z+ \overline{z}}{2}\\
	y = \frac{z- \overline{z}}{2i}
\end{align}
Un numero complesso può essere rappresentato anche in \textbf{forma polare} nel seguente modo
\begin{align}
	&\double{x = \rho \cos (\theta)}{y = \rho \sin (\theta)} \spacer \double{\rho = \sqrt{x^2 + y^2}}{\theta = \arctan (\frac{y}{x})}\firstpassage
	&\double{z =  \rho (\cos (\theta) + i\sin(\theta))}{\overline{z} = \rho (\cos (\theta) - i\sin(\theta))}
\end{align}
Possiamo inoltre usare la \textbf{formula di Eulero} per riscrivere
\begin{align}
	&e^{i\theta} = \cos(\theta)+ i \sin (\theta)\firstpassage
	&\double{z = \rho e^{+i\theta}}{\overline{z} = \rho e^{-i\theta}}\\
	&\cos (\theta) = \frac{e^{i\theta} + e^{-i\theta}}{2} \spacer x= \frac{e^{i\theta} + e^{-i\theta}}{2\rho}\\
	&\sin (\theta) = \frac{e^{i\theta} - e^{-i\theta}}{2i} \spacer x= \frac{e^{i\theta} - e^{-i\theta}}{2i\rho}
\end{align}

\newpage

\subsection{Funzioni di variabile complessa (Alessandro Marcelli)}

Una funzione di variabile complessa $f(z)$ per definizione può essere scritta come
\begin{align}
	f(z) = u(x,y) + i v(x,y) \spacer x,y, u(x,y), v(x,y) \in \R
\end{align}
In analogo col caso reale, $f(z)$ si dice \textbf{differenziabile}\cite{MfP} in $z_0 \in \C$ se il limite
\begin{align}
	\limit{\Delta z}{0} \frac{f(z_0 + \Delta z) - f(z_0)}{\Delta z}
\end{align}
\begin{enumerate}
	\item esiste
	\item è finito
	\item il suo valore non cambia in funzione della direzione dal quale lo si approccia
\end{enumerate}
La difficoltà aggiuntiva rispetto al caso reale è dovuto al fatto che in campo complesso il numero di direzioni possibili è infinito. Le condizioni sono quindi molto più restrittive del caso reale, ovvero
\begin{enumerate}
	\item Devono essere rispettate le \textbf{condizioni di Cauchy-Riemann}:
	\begin{align}
		\frac{\partial u(x,y)}{\partial x} &= +\frac{\partial v(x,y)}{\partial y}\\
		\frac{\partial u(x,y)}{\partial y} &= -\frac{\partial v(x,y)}{\partial x}		
	\end{align}
	\item Le derivate parziali prime di $u(x,y)$ e $v(x,y)$ devono essere continue
\end{enumerate}

Le funzioni di variabile complessa si dividono in due categorie:
\begin{enumerate}
	\item \textbf{funzioni a singolo valore}, ovvero che assumono lo stesso valore in $z_0$ indipendentemente dal percorso fatto per raggiungerlo. Ad esempio
	\begin{align}
		f(z) = \frac{1}{z}
	\end{align}
	\item \textbf{funzioni multivalore}, ovvero il cui valore varia a seconda del percorso fatto per raggiungere $z_0$. Ad esempio
	\begin{align}
		g(z) = \ln(z) = \ln |z| + i \arg (z)
	\end{align}
\end{enumerate}

Se la funzione è differenziabile ed è a \textbf{singolo valore} per ogni punto di un insieme $\mathcal{D}$, allora si dice che è \textbf{analitica} in questo insieme, che prende il nome di \textbf{dominio di analiticità}. All'interso di $\mathcal{D}$ essa non può assumere massimi locali.

Una funzione analitica può essere anche riscritta come (RITROVA GLI APPUNTI DI SANTINI)
\begin{align}
	f(z) = u(x,y) + iv(x,y) \to f(z) = u(z,\overline{z}) + i v(z,\overline{z})
\end{align}

Se una funzione è analitica in un punto, questo si dice \textbf{punto regolare} della funzione, altrimenti prende il nome di \textbf{punto singolare}.

Per le funzioni multivalore spesso si può "barare" utilizzando le \textbf{superfici di Riemann}, che ci permettono di usare le comode proprietà delle funzioni analitiche.

Il \textbf{teorema di Cauchy} ci dice che, per curve chiuse $\gamma$
\begin{align}
	\oint_\gamma dz \; f(z) = 0 \quad \forall \gamma \in \mathcal{D}
\end{align}
Siccome qualunque curva chiusa può essere scritta come combinazioni di curve con gli stessi estremi, questo implica che fissati gli estremi di integrazione il valore dell'integrale è indipendente dal percorso.


\newpage
\subsection{Zeri e singolarità (Alessandro Marcelli)}

\subsubsection{Zeri}

Se una funzione $f(z)$ sparisce per $z=z_0$ allora tale punto viene detto \textbf{zero della funzione}. Uno zero si dice di ordine $n$ quando
\begin{align}
	f(z_0) = \left. \frac{df(z)}{dz} \right|_{z=z_0} =  \left. \frac{d^2 f(z)}{dz^2} \right|_{z=z_0} = \dots = \left. \frac{d^{n-1}f(z)}{dz^{n-1}} \right|_{z=z_0} = 0 \spacer
	\left. \frac{d^{n}f(z)}{dz^{n}} \right|_{z=z_0} \neq 0
\end{align}

\subsubsection{Singolarità}

Le \textbf{singolarità} di una funzione sono i punti in cui  una funzione non è analitica. Qualora vi sia un solo punto nell'insieme si parla di \textbf{singolarità isolata}.
Possiamo dividerle in tre categorie
\begin{enumerate}
	\item \textbf{Singolarità eliminabile}, quando esiste finito il limite tendente ad essa.
	\item \textbf{Poli di ordine $n$}, ovvero dove la serie di Laurent della funzione ha coefficienti nulli da $b_{n+1}$ in poi.
	\item \textbf{Singolarità essenziali} quando la serie di LAurentha infinit coefficienti non nulli
\end{enumerate}

APPUNTI SANTINI DATROVARE

\subsubsection{Residui}

Se in un insieme $A$ la nostra $f(z)$ presenta singolarità isolate $z_i$, non vale più il teorema di Cauchy, e quindi non si annulla l'integrale, il cui valore viene dato dalla somma dei \textbf{residui della funzione} in tali punti
\begin{align}
	&\oint_\gamma dz \; f(z) = \sum_{i=1}^N \text{Res} (f(z), z_i)\\
	&\text{Res} (f(z), z_i) = \limit{z}{z_i} \frac{1}{(n-1)!} \left( \frac{d^{n-1}}{dz^{n-1}} \left[ (z-z_0)^n f(z) \right] \right) \spacer n = \text{ordine del polo}
\end{align}


\subsection{Indicatore Logaritmico (Davide Bufalini)}
Data una funzione $f(z)$ meromorfa ,si definisce l'\textbf{indicatore logaritmico} come
\begin{align}
	L_f(z) = \frac{d}{dz}ln(f(z)) = \frac{f'(z)}{f(z)}
\end{align}
$L_f(z)$ sarà dotata di poli semplici.

Facciamo alcune osservazioni:
\begin{enumerate}
	\item Se $f(z)$ ha $N$ poli e $K$ zeri allora
	\begin{align}
		\oint_C \frac{dz}{2\pi i} L_f(z) = \sum_{i=1}^{N} m_i - \sum_{l=1}^{M}r_l
	\end{align}
	Le quantità $m_i$ e $r_l$ sono rispettivamente le molteplicità dei poli e degli zeri di $f(z)$.
	\item Per l'indicatore logaritmico vale la seguente relazione
	\begin{align}
		\int_{z_i}^{z_f}\frac{dz}{2\pi i} L_f(z) = \frac{1}{2\pi} \Delta_c Arg(f(z))
	\end{align}
	\item In generale vale che
	\begin{align}
		\oint_C \frac{dz}{2\pi i} L_f(z) \phi(z) = \sum_{i=1}^{N} m_i\phi(a_i) - \sum_{l=1}^{M}r_l\phi(b_lcc)
	\end{align}
	Dove $a_i$ e $b_l$ sono rispettivamente i poli e gli zeri di $\phi(z)$. 
\end{enumerate}

\newpage

\subsection{Inversione e reciprocità locale (Davide Bufalini)}

Sia una $f(z)$ analitica con centro dello sviluppo in $z_0$ tale che
\begin{align}
	f(z) = \sum_{n=0}^{+\infty} a_n (z-z_0)^n	\label{eq1}
\end{align}
allora, preso un intorno di $z_0$, vi si possino definire la reciproca della funzione $\frac{1}{f}$ e la sua inversa $z^{-1}$.

\subsubsection{Funzione reciproca}

Definiamo la reciproca come
\begin{align}
	\frac{1}{f} = \sum_{k} c_k (z-z_0)^k
\end{align}
Allora per definizione avremo, considerando la \ref{eq1}
\begin{align}
	&\sum_{k} c_k (z-z_0)^k \cdot \sum_{n=0} a_n (z-z_0)^n = 1\firstpassage
	&\sum_{k,n} c_ka_n (z-z_0)^{n+k} = 1 \label{eq2}
\end{align}
Riscriviamo la \ref{eq2} come
\begin{align}
	\sum_{l=0}^{+\infty} d_l (z-z_0)^l = 1
\end{align}
definendo
\begin{align}
	l &= n+k\\
	d_l &= \sum_{n=0}^{l}c_{l-n}a_n
\end{align}
Vediamo come
\begin{align}
	1 = d_0 &= c_0a_0 \quad \rightarrow& \quad &c_0 = \frac{1}{a_0}\\
	0 = d_1 &= c_0a_1 + c_1a_0 \quad \rightarrow& \quad &c_1 = -\frac{a_1}{a_0^2} = -\frac{a_1}{a_0} c_0\\
	0 = d_2 &= c_0a_2 + c_1a_1 + c_2a_0 \quad \rightarrow& \quad &c_2 = \dots = -\frac{1}{a_0}\left( -\frac{a_2}{a_0} + \frac{a_1^2}{a_0^2} \right) \\
	\dots \nonumber
\end{align}
Andiamo ora a scrivere
\begin{align}
	\frac{1}{f} &= \frac{1}{a_0}\cdot \frac{1}{1 + \frac{a_1}{a_0}(z-z_0) + \frac{a_2}{a_0} (z-z_0)^2 + \dots} := \frac{1}{a_0} \cdot \frac{1}{1-h(z)}
\end{align}
Siccome $|h(z)| \arrowlim{z}{z_0} 0$, possiamo appoggiarci al concetto di serie geometrica
\begin{align}
	\frac{1}{f} = \frac{1}{a_0}\cdot (1 + h(z) + h^2(z) + \dots)
\end{align}

\subsubsection{Funzione inversa}

Iniziamo notando come $F(z_0) = a_0$, da cui troviamo che, definendo
\begin{align}
	g(w) = f^{-1}(w) = \sum_{n=0}^{+\infty} b_n(w-w_0)^n
\end{align}
Si ottiene
\begin{align}
	g(w_0) = f^{-1}(w_0) = b_0 = z_0
\end{align}

Possiamo quindi procedere in due modi:
\begin{enumerate}
	\item \textbf{Per serie:}
	\begin{align}
		&f(z) - f(z_0) = \sum_{n=1}^{+\infty} a_n (z-z_0)^n= w-w_0\firstpassage
		& z -z_0 = g(w) - g(w_0) = 	 \sum_{n=1}^{+\infty} b_n(w-w_0)^n	\firstpassage
		& w - w_0 = \sum_{n=1}^{+\infty} a_n (\sum_{k=1}^{+\infty} b_k (w-w_0)^k)^n
	\end{align}
	\item \textbf{Formula di Lagrange:}
	\begin{align}
		b_0 &= g(w_0) = z_0\\
		b_n &= \frac{1}{n!} \frac{d^{n-1}}{dz^{n-1}} \left. \left[ \frac{z-z_0}{f(z) - f(z_0)} \right] \right|_{z=z_0}
	\end{align}
	
\end{enumerate}

\newpage

\subsection{Espansione di Weierstrass (Davide Bufalini)}
Presa una $f(z)$ con infiniti zeri $z_j$ numerabili di ordine $\alpha_j$ che si accumulano all'infinito (e mai allo zero???) allora vale lo sviluppo
\begin{align}
	f(z) =f(0) e^{z\frac{f'(0)}{f(0)}} \prod_{n=1}^{+\infty}\left( 1 - \frac{z}{z_n} \right)^{\alpha_n} e^{\alpha_n \frac{z}{z_n}}
\end{align}

\subsection{Funzioni speciali (Alessandro Marcelli)}

\subsubsection{Funzione Gamma di Eulero}
\begin{align}
	\Gamma(z) &= \int_{0}^{\infty} dt \; e^{-t} t^{z-1} = \dots =  \quad &\text{Integrale Euleriano di II tipo}\\
	&= \frac{1}{z} \prod_{k=1}^{\infty} \left( 1+ \frac{1}{k} \right)^z \left( 1+ \frac{z}{k} \right)^{-1}
\end{align}
Gode della proprietà	
\begin{align}
	&\Gamma(z) \Gamma(1-z) = \frac{\pi}{\sin(\pi z)} \firstpassage
	&\Gamma\left(\frac{1}{2}\right) \Gamma\left(\frac{1}{2}\right) = \pi \rightarrow \Gamma \left( \frac{1}{2} \right) = \sqrt{\pi} \\
	&\Gamma\left(\frac{1}{2} + \xi\right) \Gamma\left(\frac{1}{2} - \xi\right) = \frac{\pi}{\cos(\pi \xi)}\\
	&\sqrt{\pi} \Gamma(2z) = 2^{2z-1} \Gamma(z) \Gamma \left( z + \frac{1}{2} \right)\\
	&\Gamma(\overline{z}) = \overline{\Gamma(z)}
\end{align}
In campo complesso si può prolungare tramite il cammino di Hankel, e si arriva ad ottenere
\begin{align}
	\Gamma(n) = (n-1)!
\end{align}

\subsubsection{Funzione Digamma}
\begin{align}
	\psi(z) = \frac{\Gamma'(z)}{\Gamma(z)} = \frac{d}{dz} \ln \Gamma (z)
\end{align}
\subsubsection{Funzione beta di Eulero}
\begin{align}
	B(p,q) &= \int_{0}^{1} dt \; t^{p-1} (1-t)^{q-1} = \dots =  \quad &\text{Integrale Euleriano di I tipo}\\
	&= \frac{\Gamma(p)\Gamma(q)}{\Gamma(p+q)}
\end{align}

\subsubsection{Funzione zeta di Riemann generalizzata}

Sono stanco capo.



\newpage

\newpage
\subsection{Espansioni asintotiche (Alessandro Marcelli, Paolo Proia)}

\subsubsection{Definizione molto generale (Alessandro Marcelli)}

Lo sviluppo in serie può essere esteso anche al caso in cui la funzione oggetto di studio $f(z)$ non sia analitica in $z_0$, trovando uno sviluppo $f(z) \sim \sum_{n=1}^{\infty} a_n f_n(z)$ che approssima "bene" il comportamento della funzione in un intorno di $z_0$ \cite{MMF}, ovvero che valgono le due seguenti proprietà:
\begin{enumerate}
	\item il resto della serie $R_N(z) = f(z) - S_N(z)$ è tale che $\limit{z}{z_0} \frac{|R_N(z)|}{|f_N(z)|} = 0 \quad \forall N\in \N$
	\item la serie fornisce una buona approssimazione di $f(z)$ solo in determinate regioni del piano complesso
\end{enumerate}
L'approssimazione che si va a trovare sarà tanto più buona tanto più grande è $x$, e si lavora quindi per $x \to + \infty$. Nel caso ci si trovi nel caso $x \to -\infty$ bisogna fare un cambio di variabile.

Il contributo maggiore sarà dato dai primi termini dell'espansione, motivo per cui di solito ci si ferma al secondo termine.

Nel nostro caso ci interessiamo della famiglia di funzioni integrali del tipo
\begin{align}
	F(x) = \int_{a}^{b} dt \; e^{x\phi(t)}g(t) \label{lol0}
\end{align}

\subsubsection{Termine Leading: Metodo di Laplace (Alessandro Marcelli)}

Se interessa solo il primo termine dell'espansione, detto \textbf{dominante}, basta sviluppare al secondo ordine $\phi(t)$ e $g(t)$ nel punto di massimo della prima, risolvere l'integrale con questa approssimazione e prendere il primo termine, come si vede nell'esempio svolto del paragrafo \ref{es1}.

\subsubsection{Metodo risolutivo generalizzato (Paolo Proia)}

Qualora servano termini successivi (di solito ci si ferma al termine Next-to-Leading) la situazione si complica, in quanto non basta sviluppare al secondo ordine e bon, in quanto ci sono casi in cui uno dei due termini può essere nullo (funzioni trigonometriche my beloved). Il procedimento si snoda quindi:
\begin{enumerate}
	\item Trovare massimo per \(\phi(t)\) (chiamiamo \(t_0\))
	\item Espandere \(g(t)\) intorno a \(t_0\) per 2 o 3 termini
	\item Prendere nota dell'esponente dell'ultimo termine (definiamo come  \(n\)) 
	\item Parametrizzare come $\phi(t) - \phi(t_0)=-\tau^2 \label{lol1}$
	ed espandere \(\phi(t)\) intorno a $t_0$ fino ad ordine \(n\)
	\item Trovare cambio di variabile da \(t\) a \(\tau\), imponendo $t - t_0 = h(\tau) = \sum_i^{n+1} c_i \tau^i$
	\item Sostituiamo nella \refeq{lol1} tenendo i termini fino a \(\tau^{n+1}\)
	\item Imporre l'uguaglianza tra i coefficenti con la stessa potenza di \(\tau\) a dx e sx, trovando così \(h(\tau)\)
	\item Essendo \(h(\tau) = t + cost. \) abbiamo che \(\dot{h}d\tau = dt\) e abbiamo così terminato il cambio di variabile
	\item Sostituiamo nella \ref{lol0}
	\begin{align}
		&\phi(t) = \phi(t_0) - \tau^2\\
		&dt=\dot{h}d\tau\\
		&g(t) \to g(h(\tau)) \label{lol2}
	\end{align}
	Nella \ref{lol2} usiamo direttamente l'espansione in serie del punto 2
	\item Svolgiamo il prodotto \(\dot{h} \cdot g(h(\tau))\), sostituiamo nell'integrale e teniamo i primi $n$ termini il cui integrale è non nullo (nel caso Next-to-Leading i primi 2)
\end{enumerate}

\textbf{NOTA BENE:} qualora una delle due funzioni sia una trigonometrica elevata a potenza conviene sviluppare solo la trigonometrica e mettere a potenza lo sviluppo, e fare altri magheggi
quali utilizzare le relazioni trigonometriche per fare il meno conti possibile.

\section{Calcolo inverse (Davide Bufalini)}
\subsection{Numeri di Eulero}

Data la relazione
\begin{align}
	\frac{1}{\coth (z)} &= \sum_{n=0}^{+\infty} \frac{E_n}{n!}z^n\\
	E_{2n+1} &= 0 \quad \forall n\\
	E_n &= \text{numeri di eulero}
\end{align}

\subsection{Numeri di Bernoulli}
\newpage

\section{Espansione di Mittag-Leffler (Davide Bufalini)}

Presa una $f(z)$ analitica nell'origine e con infiniti poli semplici che si accumulano all'infinito, vale la seguente approssimazione
\begin{align}
	f(z) &= f(0) + \sum_{n=1}^{+\infty} R_n \cdot \left( \frac{1}{z-z_n} + \frac{1}{z_n} \right)\\
	R_n &= Res(f, z_n)
\end{align}


\section{Esempio: cotangente}

\subsubsection{Calcolo dell'espansione}

La funzione  
\begin{align}
	f(z) = \cot(z)
\end{align}
ha poli in $z_n = n\pi$ con $n\in \Z$, ma \textbf{non} è analitica in $z=0$.

Per eliminare la singolarità in 0 considero allora la funzione
\begin{align}
	f(z) = \cot(z) - \frac{1}{z}
\end{align}
I cui residui saranno
\begin{align}
	R_n = \limit{z}{n\pi} \left[ (z-n\pi) \cdot \frac{z\cot(z) -1}{z} \right] = \dots = 1  
\end{align}
Applicando lo sviluppo ottengo
\begin{align}
	\cot(z) - \frac{1}{z} &= \sum_{n\neq 0} \left( \frac{1}{z-n\pi} + \frac{1}{n\pi}\right) \firstpassage
	\cot(z) &= \frac{1}{z} + \sum_{n\neq 0} \left( \frac{1}{z-n\pi} + \frac{1}{n\pi}\right) = \nonumber\\
	&= \frac{1}{z} + \sum_{n>0} \left[ \frac{1}{z-n\pi} + \frac{1}{n\pi} - \left( \frac{1}{-z-n\pi} + \frac{1}{n\pi} \right) \right] = \nonumber\\
	&= \dots  = \nonumber\\
	&= \frac{1}{z} + \sum_{n>0} \frac{2z}{z^2 - (n\pi)^2}
\end{align}

\newpage

\subsubsection{Verifica dell'espansione}

Dimostrare la validità della relazione
\begin{align}
	\cot(z) = \frac{1}{z} + \sum_{n>0} \frac{2z}{z^2 - (n\pi)^2}
\end{align}

Iniziamo dimostrando l'analiticità. Come abbiamo visto prima, dobbiamo prendere
\begin{align}
	f(z) = \cot(z) - \frac{1}{z}
\end{align}
Andiamo quindi a calcolarne il limite in 0
\begin{align}
	\limit{z}{0} \cot(z) \frac{1}{z} &= \limit{z}{0} \frac{\frac{z\cos(z)}{\sin(z)} -1}{z} = \nonumber\\
	&= \limit{z}{0} \frac{z\cos(z) - \sin(z)}{z\sin (z)} = \nonumber\\
	&= \limit{z}{0}\frac{\cos(z) \cdot [z - \tan (z)]}{z - \sin(z)} = \limit{z}{0} \frac{\cot(z)}{z} \cdot(z-\tan(z)) = 1\cdot 0 = 0
\end{align}
Verificata l'analiticità, procediamo a studiare poli e residui della funzione. 

Avremo dei poli semplici quando $\sin(z) = 0$, e qundi per $z_n=n\pi$, con $n=0$ \textbf{escluso}, in quanto vi si annulla la funzione. Ne segue che i residui saranno
\begin{align}
	Res(f,z_n) = \limit{z}{n\pi}  (z-n\pi) \cdot \frac{z\cot(z) -1}{z}
\end{align} 
Facendo il cambio di variaible $u=z-n\pi$ otteniamo
\begin{align}
	Res(f,z_n) = \limit{u}{0} u \cdot \frac{(u+n\pi)\cot(u+n\pi) -1}{u+n\pi} \label{eq3}
\end{align} 
Se però osserviamo un attimo il termine $\cot(u+n\pi)$ notiamo come lo si possa manipolare nel seguente modo
\begin{align}
	\cot(u+n\pi) &= \frac{\cos(u+n\pi)}{\sin(u+n\pi)} = \frac{\cos(u)\cdot(-1)^n}{\sin(u)\cdot(-1)^n} = \frac{\cos(u)}{\sin(u)} = \cot(u)
\end{align}
Possiamo quindi riscrivere la \ref{eq3} come
\begin{align}
	Res(f,z_n) &= \limit{u}{0} u \cdot \frac{(u+n\pi)\cot(u) -1}{u+n\pi} \simeq \limit{u}{0} u\cdot \frac{(u+n\pi)\cdot \frac{1}{u} -1}{u+n\pi} = \nonumber\\
	&= \left. \frac{u+n\pi -u}{u+n\pi} \right|_{u=0} = 1 \quad \forall n\in \N
\end{align} 

Possiamo quindi applicare lo sviluppo
\begin{align}
	f(z) &= \sum_{n\neq 0} \left( \frac{1}{n-n\pi} + \frac{1}{n\pi} \right) = \nonumber\\
		 &= \sum_{n=-\infty}^{-1} \left( \frac{1}{n-n\pi} + \frac{1}{n\pi} \right) + \sum_{n=1}^{+\infty} \left( \frac{1}{n-n\pi} + \frac{1}{n\pi} \right) = \nonumber \\
		 &= \sum_{n>0} \left[ \frac{1}{z-n\pi} + \frac{1}{n\pi} - \left( \frac{1}{-z-n\pi} + \frac{1}{n\pi} \right) \right] = \nonumber\\
		 &= 2z\sum_{n=1}^{+\infty} \frac{1}{z^2 - (n\pi)^2}
\end{align}
E la tesi è così dimostrata.

\newpage

\subsection{Esempio: $\sin^{-2}(z)$}

Utilizziamo l'integrale (di Cauchy? Chiedere)
\begin{align}
	I_n = \oint_{Q_n} \frac{d\zeta}{(\zeta -z) \sin^2(\zeta)}
\end{align}
Studiando i poli otteniamo
\begin{align}
	\zeta_0 &= z \quad &\text{polo semplice}\\
	\zeta_n &= n\pi \; n\in \N  \quad &\text{poli doppi}
\end{align}
Siccome $I_n \arrowlim{n}{+\infty} 0$ abbiamo che
\begin{align}
	0 &= \sum_{n\in \N} Res(f(\zeta), n\pi) + Res(f(\zeta), z) =\nonumber\\
	  &= \sum_{n\in \N} Res(f(\zeta), n\pi) + \frac{1}{\sin^2(z)}  \label{eq4}
\end{align}
Da cui otteniamo
\begin{align}
	  \frac{1}{\sin^2(\zeta)} &= -\sum_{n\in \N} Res(f(\zeta), n\pi)
\end{align}
Dato che
\begin{align}
	Res(f(\zeta), n\pi) &= \limit{\zeta}{n\pi} \frac{d}{d\zeta} \frac{(\zeta - n\pi)^2}{(\zeta - z) \sin^2(\zeta)} \firstpassage
	\double{u=\zeta - n\pi}{\zeta = u + n\pi} \nextpassage
	Res(f(\zeta), n\pi) &= \limit{u}{0} \frac{d}{du} \frac{u^2}{(u + n\pi - z) \sin^2(u + n\pi)} =  \limit{u}{0} \frac{d}{du} \frac{u^2}{(u + n\pi - z) (-1)^{2n} \sin^2(u)}= \nonumber\\
	&= \limit{u}{0} \frac{d}{du} \frac{u^2}{(u + n\pi - z) \left(u -\frac{u^3}{3!} + \dots\right)^2} = \left. \frac{d}{du} \frac{u^2}{(u + n\pi - z) \left(u -\frac{u^3}{3!} + \dots\right)^2} \right|_{u=0} = \nonumber \\
	&= \left. \frac{d}{du} \frac{1}{(u + n\pi - z) \left(1 -\frac{u^2}{3!} + \dots\right)^2} \right|_{u=0} = \left. \frac{d}{du} \frac{1}{(u + n\pi - z) \left(1 -\frac{u^2}{3!} + \dots\right)^2} \right|_{u=0} = \nonumber \\
	&= \left. \frac{d}{du} \frac{\left(1 +\frac{u^2}{3!} - \dots\right)^2}{(u + n\pi - z) } \right|_{u=0} = \left. \frac{d}{du} \frac{\left(1 +\frac{u^2}{3} + \dots\right)}{(u + n\pi - z) } \right|_{u=0} = \nonumber \\
	&= \left. \frac{\left( \frac{2}{3} u + \dots \right) (u + n\pi-z ) - \left(1 + \frac{u^2}{3}\right)}{(u+ n\pi -z)^2} \right|_{u=0} = -\frac{1}{(n\pi -z)^2}
\end{align}
La \ref{eq4} diventa
\begin{align}
	\frac{1}{\sin^2(z)} = \sum_{n\in \N} \frac{1}{(n\pi -z)^2}
\end{align}

\newpage

\section{Sommerfeld-Watson (Davide Bufalini)}

Utile strumento per il calcolo delle somme di serie. Sia una funzione $g(z)$ analitica ovunque tranne che in singolarità polari isolate $z_k$ e sia 
\begin{align}
	\limit{|z|}{+\infty} |zq(z) =0|
\end{align}
Allora valgono le seguenti relazioni
\begin{align}
	\sum_{n\in \Z} (-1)^n g(n) &= -\pi \sum_{k} Res\left( \frac{g(z)}{\sin(\pi z)}, z=z_k \right)\\
	\sum_{n\in \Z} g(n)  &= -\pi \sum_{k} Res\left( g(z)\cot(\pi z), z=z_k \right)
\end{align}

\subsection{Esempio 1}

Calcolare la somma della serie
\begin{align}
	S(a) = \sum_{n=1}^{+\infty} \frac{(-1)^n}{n^2 + a^2} \spacer a \in \R \backslash \{0\}
\end{align}
Iniziamo notando che possiamo scrivere
\begin{align}
	\sum_{n=1}^{+\infty} \frac{(-1)^n}{n^2 + a^2} = 2S(a) + \frac{1}{a^2}
\end{align}
Ponendo
\begin{align}
	g(z)=\frac{1}{n^2 + a^2}
\end{align}
Otteniamo
\begin{align}
	&z^2 + a^2= 0 \firstpassage
	&z_p= \pm ia	
\end{align}
E possiamo quindi applicare SW
\begin{align}
	&\limit{z}{\pm ia} \frac{z\pm ia}{z^2+a^2} \cdot \frac{1}{\sin(\pi z)} = \dots = -\frac{1}{2a\sinh(\pi a)} \firstpassage
	&\frac{(-1)^n}{n^2 + a^2} = -\pi Res \left(\frac{g(z)}{\sin(\pi z)}, z_p\right) = -\frac{\pi}{2a\sinh(\pi a)} \nextpassage
	&S(a) = -\frac{1}{2a^2} + \frac{\pi}{4a\sinh(\pi a)}
\end{align}




\newpage

\section{Espansioni asintotiche (Davide Bufalini, Alessandro Marcelli, Paolo Proia)}

\subsection{Esempio 1: metodo generalizzato (Paolo Proia)}

Sia la seguente funzione integrale
\begin{align}
	I(t)    &= \int_{1}^{+\infty} dt \; e^{-x \frac{t^2}{2}}t^x \frac{1}{t^2 + 1} = \int_{1}^{+\infty} dt \; e^{-x \frac{t^2}{2}} e^{x\ln(t)} \frac{1}{t^2 + 1} = \int_{1}^{+\infty} dt \; e^{x\left(\ln(t) -\frac{t^2}{2}\right)} \frac{1}{t^2 + 1}\\
	\phi(t) &= \ln(t) - \frac{t^2}{2} \\
	g(t)    &= \frac{1}{t^2 + 1}
\end{align}

\begin{enumerate}
	\item Trovare massimo per \(\phi(y)\) (chiamiamo \(y_0\))
	\begin{align}
		\dot{\phi}(t) &=\frac{1}{t} - t = \frac{1- t^2}{t} = 0 \to t = \pm 1\\
		\ddot{\phi}(t) &= -\frac{1}{t^2} - 1 = -\frac{t^2+1}{t^2}  \\
		\dddot{\phi}(t) &= \frac{2}{t^3}
	\end{align}
	Escoludiamo il risulato negativo, siccome $\phi(t)$ non è definito in quel punto. Abbiamo quindi
	\begin{align}
		t_0=+1 \quad ; \quad\phi_0 = -\frac{1}{2}
	\end{align}
	\item Espandiamo \(g(t)\) intorno a \(t_0\)
	\begin{align}
		g(t) &\simeq g(t_0) + g(t_0)\cdot(t-t_0) = \frac{1}{2} - \frac{1}{2} (t-1) = 1-\frac{t}{2} 
	\end{align}
	\item Notiamo come ci siamo fermati per \(n=1\)
	\item Parametrizziamo
	\begin{align}
		&\phi(t)= -\frac{1}{2} + 0\cdot(t-1) - \frac{1}{2}\cdot 2 \cdot(t-1)^2  + \frac{1}{3!} \cdot 2 (t-t_0)^3= -\frac{1}{2} - (t-1)^2 + \frac{1}{3} (t-t_0)^3= -\tau^2
	\end{align}
	\item Troviamo cambio di variabile da \(t\) a \(\tau\), fermandoci al terzo ordine, essendo lo sviluppo in t al 3o ordine
	\begin{align}
		&t-t_0 = t-1 = c_1 \tau + c_2 \tau^2 + c_3 \tau^3 + O(\tau^4)\\
		&\phi(t) = - \frac{1}{2} - (c_1 \tau + c_2 \tau^2 + c_3 \tau^3)^2+ \frac{1}{3} (c_1 \tau + c_2 \tau^2 + c_3 \tau^3)^3
	\end{align}
	\item Andiamo quindi a sostituire
	\begin{align}
		\phi(t) + \frac{1}{2} &=  - (c_1 \tau + c_2 \tau^2 + c_3 \tau^3)^2+ \frac{1}{3} (c_1 \tau + c_2 \tau^2 + c_3 \tau^3)^3 = \dots = \nonumber\\
		&= -c_1^2 \tau^2 - 2c_1c_2 \tau^3 + \frac{1}{3}c_1^3 \tau^3
	\end{align}
	\item Andiamo ora a confrontare
	\begin{align}
		\phi(t) + \frac{1}{2} &= -\tau^2\\
		\phi(t) + \frac{1}{2} &= -c_1^2 \tau^2 - 2c_1c_2 \tau^3 + \frac{1}{3}c_1^3 \tau^3
	\end{align}
	Ne segue che
	\begin{align}
		&-c_1^2 \tau^2 = -\tau^2 &\to c_1 = 1\\
		&-2c_1c_2 \tau^3 + \frac{1}{3}c_1^3 \tau^3=0 &\to -2c_2 + \frac{1}{3} = 0 \to c_2 = \frac{1}{6}
	\end{align}
	Abbiamo così trovato
	\begin{align}
		t-1 = h(\tau) = \tau + \frac{1}{6}\tau^2
	\end{align}
	\item Sostuiamo e troviamo
	\begin{align}
		t-1 = \tau + \frac{1}{6}\tau^2 \to d(t-1) = dt = \left( 1 + \frac{1}{3} \tau \right) d\tau
	\end{align}
	\item Sostituiamo infine nella nostra funzione integrale
	\begin{align}
		I(x) &= \int_{0}^{+\infty} d\tau \; e^{-x \left( \tau^2 + \frac{1}{\tau} \right)} \left( 1 + \frac{1}{3} \tau \right) \left(\frac{1}{2} - \frac{\tau}{2}\right) = \nonumber\\
		&= \int_{0}^{+\infty} d\tau \; e^{-x \left( \tau^2 + \frac{1}{\tau} \right)} \left( \frac{1}{2}- \frac{1}{2}\tau + \frac{1}{6} \tau - \frac{1}{6} \tau^2 \right) = \nonumber\\
		&= \int_{0}^{+\infty} d\tau \; e^{-x \left( \tau^2 + \frac{1}{\tau} \right)} \left( \frac{1}{2} - \frac{1}{3} \tau \right) = \nonumber\\
		&= e^{-\frac{x}{2}}\int_{0}^{+\infty} d\tau \; e^{-x\tau^2} \left( \frac{1}{2} - \frac{1}{3} \tau \right)
	\end{align}
	\item abbiamo quindi
	\begin{align}
		I(x) &= e^{-\frac{x}{2}} \left( \frac{1}{2} \int_{0}^{+\infty} d\tau \; e^{-x\tau^2} - \frac{1}{3} \int_{0}^{+\infty} d\tau \; e^{-x\tau^2}\tau \right)
	\end{align}
\end{enumerate}

\newpage

\subsection{Esempio 2 (Davide Bufalini) \label{es1}}

Calcolare per $x\rightarrow +\infty$ i primi due termini dell'espansione per la funzione integrale
\begin{align}
	F(x) = \int_{0}^{\frac{\pi}{2}} dt \; e^{x\cos(t)}\sin^3(t)
\end{align}

Partiamo dal \textbf{termine Leading}. Siccome abbiamo
\begin{align}
	\phi(t) &= \cos(t) \\
	g(t) &= \sin^3(t)
\end{align}
Andiamo a cercarne il punto di massimo, che troviamo in
\begin{align}
	&\frac{d \phi(t)}{dt} = -\sin(t) \firstpassage
	&\sin(t) = 0 \nextpassage
	&t_0=0
\end{align}
Andiamo quindi a sviluppare
\begin{align}
	\phi(t) &\simeq 1- \frac{t^2}{2} + o(t^3)  \\
	g(t) &\simeq \left( t - \frac{t^3}{6} \right)^3 \simeq t^3 \quad \text{termine leading}
\end{align}
E otteniamo
\begin{align}
	F(x) &\simeq \int_{0}^{\frac{\pi}{2}} dt \; e^{x\left(1- \frac{t^2}{2}\right)}t^3 = \nonumber\\
	&= \int_{0}^{+\infty} dt \; e^x e^{-x\frac{t^2}{2}}t^3
\end{align}
Applicando la sostituzione
\begin{align}
	&y= \frac{t^2}{2} \quad \leftrightarrow \quad t^2 = 2y \\
	&dy = tdt
\end{align}
Possiamo arrivare ad ottenere il termine cercato
\begin{align}
	F(x) &= \int_{0}^{\frac{\pi}{2}} dy \; e^x e^{-xy}2y = \nonumber\\
		 &= 2e^x\int_{0}^{+\infty} dy \;e^{-xy}y = \nonumber\\
		 &= 2e^x \frac{\Gamma(2)}{x^2} = \frac{2e^x}{x^2}
\end{align}

Per quanto riguarda il termine \textbf{Sub-leading}, andiamo a parametrizzare la $\phi(t)$ nel seguente modo
\begin{align}
	&\phi(t) - \phi(t_0) = -\tau^2 \firstpassage
	&\cos(t) - 1 = -\tau^2 \nextpassage
	&t= \arccos(i-\tau^2) \firstpassage
	&dt = -\frac{d\tau}{\sqrt{1-(1-\tau^2)^2}}\cdot(-2\tau) = \frac{2\tau d\tau}{\sqrt{2\tau^2-\tau^4}} = \frac{2d\tau}{\sqrt{2-\tau^2}}
\end{align}
Andiamo così a trovare i primi due termini dell'espansione
\begin{align}
	F(x) &\simeq \int_{0}^{+\infty} \frac{2d\tau}{\sqrt{2-\tau^2}} \; e^{x\left(1- \tau^2\right)}(\sqrt{1-cos^2(t)})^3 = \nonumber\\
	&= \int_{0}^{+\infty} \frac{2d\tau}{\sqrt{2-\tau^2}} \; e^{x\left(1- \tau^2\right)}(\sqrt{1-(1-\tau^2)^2})^3 = \nonumber\\
	&=\int_{0}^{+\infty} \frac{2d\tau}{\sqrt{2-\tau^2}} \; e^{x\left(1- \tau^2\right)}(\sqrt{2\tau^2-t^4})^3 = \nonumber\\
	&=\int_{0}^{+\infty} \frac{2d\tau}{\sqrt{2-\tau^2}} \; e^{x\left(1- \tau^2\right)}(\tau\sqrt{2-\tau^2})^3 = \nonumber\\
	&=\int_{0}^{+\infty} 2d\tau \; e^{x\left(1- \tau^2\right)}\tau^3 (2-\tau^2) = \nonumber\\
	&=2e^x \left[ 2\int_{0}^{+\infty}d\tau \; e^{-x\tau^2} \tau^3 - \int_{0}^{+\infty} d\tau\; e^{-x\tau^2}\tau^5 \right] = \nonumber\\
	&= 2e^x\left[ 2\frac{\Gamma(2)}{x^2} - \frac{1}{2} \frac{\Gamma(3)}{x^3} \right] = \nonumber \\
	&= \frac{2e^x}{x^2} - \frac{2}{2} \frac{e^x 2!}{x^3} =\nonumber\\
	&= \frac{2e^x}{x^2} -\frac{2e^x}{x^3}
\end{align}



\subsection{Esempio 3 (Davide Bufalini)}

Calcoliamo i termini \textbf{Leading} e \textbf{Subleading} per la funzione
\begin{align}
	I(x) = \int_\R dt \; e^{-x \cosh(t)}
\end{align}
Iniziamo individuando le  nostre funzioni
\begin{align}
	\phi(t) &= -\cosh(t)\\
	g(t) &= 1 \firstpassage
	\frac{d\phi(t)}{dt} &= \sinh(t) = 0 \quad \rightarrow \quad t_0 = 0
\end{align}

Inziamo col termine \textbf{Leading}. Sviluppando intorno a $t_0$ otteniamo
\begin{align}
	&\phi(t) \simeq -\left( 1 + \frac{t^2}{2} \right)\firstpassage
	&I(x) = \int_\R dt e^{-x}e^{-x \frac{t^2}{2}} = e^{-x} \frac{2\pi}{x}	
\end{align}

Per quanto riguarda il termine \textbf{Subleading} andiamo a parametrizzare
\begin{align}
	&\phi(t) - \phi(t_0) = -\tau^2 \firstpassage
	& \cosh(t) -(-1) = -\tau^2
\end{align}
Siccome abbiamo
\begin{align}
	dt = \left( \frac{dt}{d\tau} \right) d\tau
\end{align}
Dobbiamo trovare una espressione per $t(\tau)$ per il calcolo ello Jacobiamo.

Siccome abbiamo $t_0 = 0$ andiamo a sviluppare per $t$ piccoli
\begin{align}
	&\cosh(t) = 1 + \frac{t^2}{2} + \frac{t^4}{24} + \dots \firstpassage
	&\cancel{1} + \frac{t^2}{2} + \frac{t^4}{24} + \dots = \cancel{1} + \tau^2 \nextpassage
	&\frac{t^2}{2} \left( 1 + \frac{t^2}{12} \right) = \tau^2 \firstpassage
	&t^2 = \frac{2\tau^2}{1 + \frac{t^2}{12}} = 2\tau^2 \left( 1 - \frac{t^2}{12} + \left( \frac{t^2}{12} \right)^2 + \dots \right) \simeq 2\tau^2 - 2\tau^2 \frac{t^2}{12} \firstpassage
	&t^2 \left( 1 + \frac{\tau^2}{6} \right) = 2\tau^2 \nextpassage
	&t^2=\frac{2\tau^2}{1 + \frac{\tau^2}{6}}\nextpassage
	&t=\frac{\sqrt{2}\tau}{\sqrt{1 + \frac{\tau^2}{6}}} \simeq \sqrt{2}\tau \left( 1 - \frac{1}{2} \frac{\tau^2}{6} \right) = \sqrt{2}\tau \left( 1 - \frac{\tau^2}{12} \right)
\end{align}
Dunque otteniamo
\begin{align}
	t &= \sqrt{2} \tau - \frac{\sqrt{2}}{12}\tau^3 \firstpassage
	dt &= \left( \sqrt{2} - \frac{\sqrt{2}}{4}\tau^2 \right)d\tau 
\end{align}

Possiamo quindi finalmente sostituire
\begin{align}
	I(x) &= \int_\R dt \; e^{-x} e^{-\frac{t^2}{2} x} = \nonumber \\
		 &= e^{-x} \int_\R d\tau \; e^{-x\tau^2}  \left( \sqrt{2} - \frac{\sqrt{2}}{4}\tau^2 \right) = \nonumber \\
		 &= e^{-x}\sqrt{2} \left[ \int_\R d\tau \; e^{-x\tau^2}   -\int_\R d\tau \;e^{-x\tau^2}  \frac{1}{4}\tau^2  \right]= \nonumber \\
		 &= e^{-x}\sqrt{2} \left[ \sqrt{\frac{\pi}{x}}   - \frac{1}{4}\cdot\frac{1}{x} \cdot \frac{1}{2} \cdot \sqrt{\frac{\pi}{x}}  \right]= \nonumber \\
		 &=e^{-x}\sqrt{\frac{2\pi}{x}} - \frac{1}{8x}e^{-x}\sqrt{\frac{2\pi}{x}}= \nonumber \\
		 &=e^{-x}\sqrt{\frac{2\pi}{x}}\left[1 - \frac{1}{8x}\right]
\end{align}

\newpage

\subsection{Esempio 4 (Davide Bufalini)}

Data la funzione
\begin{align}
	\int_{\frac{\pi}{2}}^{\frac{3}{4}\pi} dt \; e^{-\frac{x}{\sin(t)}} (1 + \cot (t))
\end{align}
se ne calcoli l'espansione.

Iniziamo trovando il punto di sella
\begin{align}
	&\phi(t) = -\frac{1}{\sin(t)}\firstpassage
	&\frac{d\phi}{dt} = \frac{\cos (t)}{\sin^2 (t)} = 0 \firstpassage
	& t_0 = \frac{\pi}{2}
\end{align}
Siccome il punto cade su uno degli estremi, ci basta considerare $t(\tau) \sim o(\tau^2)$
Parametrizziamo
\begin{align}
	&\phi(t) - \phi(t_0) = -\tau^2\firstpassage
	&-\frac{1}{\sin (t)}-\left(-\frac{1}{\sin \left( \frac{\pi}{2}\right)}\right) = -\tau^2 \nextpassage
	&-\frac{1}{\sin (t)} = 1 +\tau^2\nextpassage
	&\sin (t) = -\frac{1}{1+\tau^2} = 1 - \tau^2 + \tau^4 + \dots \nextpassage
	&\frac{1}{2} \left( t -\frac{\pi}{2} \right)^2 = \tau^2 + o(\tau^3) \label{kekw}
\end{align}
Espandendo $\tau$ si ha che
\begin{align}
	 t -\frac{\pi}{2} = c_1 \tau + c_2 \tau^2 + c_3 \tau^3 + \dots \label{kukw}
\end{align}
Sostituendo nella \ref{kekw}
\begin{align}
&\frac{1}{2} \left( c_1 \tau + c_2 \tau^2 \right)^2 = \tau^2 \firstpassage
&c_1^2 \tau^2 + 2c_1 c_2 \tau^3 + c_2^2 \tau^4 = 2 \tau^2\nextpassage
&\double{c_1 = &\sqrt{2}}{c_2 = &0}
\end{align}
Sostituendo nella \ref{kukw} otteniamo
\begin{align}
	&t -\frac{\pi}{2} = \sqrt{2}\tau + o(\tau^3)	\firstpassage
	&dt = \sqrt{2}d\tau
\end{align}
Sviluppiamo ora $g(t)$ intorno a $t_0$
\begin{align}
	g(t) = 1 + \cot(t) = 1 - \left( t -\frac{\pi}{2} \right) \sim 1 - \sqrt{2}\tau +o(\tau^3)
\end{align}
Possiamo quindi riscrivere la nostra funzione integrale come
\begin{align}
	I(x) &= \int_{0}^{+\infty} \sqrt{2} d\tau \; e^{-x(1+\tau^2)}(1 - \sqrt{2}\tau) = \nonumber\\
	&= \sqrt{2}e^{-x} \int_{0}^{+\infty}  d\tau \; e^{-\tau^2}(1 - \sqrt{2}\tau) = \nonumber\\
	&=e^{-x} \left[ \sqrt{\frac{\pi}{2x}} - \frac{1}{x} \right]
\end{align}


\newpage

\subsection{Metodo del punto di sella (Davide Bufalini)}

Abbiamo finora visto integrali sulla retta reale. Qualora si abbia una generica curva $\gamma \in \C$ il procedimento si complica leggermente. 

Presa una funzione integrale della forma
\begin{align}
	I(x) = \int_\gamma dt \; e^{x\phi(t)} g(t)
\end{align}
Qualora $\phi(t)$ e $g(t)$ siano analitiche in un dominio $\mathit{D}$ e si abbia $\gamma \subseteq \mathit{D}$ abbiamo un problema. Infatti, riscrivendo la $\phi(t)$ nella seguente forma
\begin{align}
	\phi(t) &= u(t) + iv(t)
\end{align}
All'interno del dominio non è detto che $v(t)$ sia costante, il che ci impedisce di restringerci al caso reale. Inoltre, per $t \in \gamma$ il termine $e^{iv(t)}$ oscilla fortemente, portanto la $I(x)$ ad essere mediata a 0. 

Cerchiamo un modo per rendere costante la $v(t)$ e rendere massima la $u(t)$, in modo da rispettare il comportamento asintotico.
Il procedimento si snoda nei seguenti passaggi
\begin{enumerate}
	\item Riscriviamo la $\phi(t)$ come
	\begin{align}
		\phi(t) = \phi(x,y) = u(x,y) + iv(x,y)
	\end{align}
	Possiamo farlo in più modi
	\begin{enumerate}
		\item Coordinate cartesiane, sostituendo $t = x + iy$
		\item Coordinate polari, sostituendo $t = \sqrt{x^2 + y^2}\cdot e^{i \arctan \left(\frac{x}{y}\right)}$
	\end{enumerate}
	\item Cerchiamo il punto di sella $t_0$ di $\phi(t)$ tale
	\begin{align}
		\phi(t_0) &= 0 \\
		\ddot{\phi}(t_0) &: \ddot{u}(t_0) <0 
	\end{align}
	\item Cerchiamo quindi i percorsi a fase costante passanti per $t_0$, ovvero ponendo $v(t)= v(t_0)$, da cui segue $Im(\phi(t)) m= Im(\phi(t_0))$. Una volta trovati questi cammini, vediamo se è possibile deformare la curva $\gamma$ su un cammino a fase costante $\gamma^*$ dove $\ddot{u}(t_0) <0$  
	\item Una volta trovato questo cammino, risolviamo con i metodi noti per il caso reale
	
\end{enumerate}

\subsection{Esempio 1}

Calcoliamo il termine leading per l'espansione asintotica  della funzione integrale
\begin{align}
	F(x) &= \int_\R dy \; e^{-x[2y^2 -(y-i)^2]} \frac{1}{y^2 + 2}\\
	g(y) &=  \frac{1}{y^2 + 2}\\
	\phi(y) &= 2y^2 -(y-i)^2
\end{align}

Iniziamo trovando il punto di sella di $\phi(y)$, e calcoliamo preliminarmente
\begin{align}
	\phi(y) &=  (y-i)^2 -2y^2 = y^2 - 2iy -1 -2y^2 = -y^2 - 2iy -1 \\
	\dot{\phi}(y) &= 2y + 2i\\
	\ddot{\phi}(y) &= 2
\end{align}
Troviamo quindi che
\begin{align}
	&2y + 2i = 0 \firstpassage
	&y_0=-i\firstpassage
	&y_0= (0,-1)
\end{align}

Passiamo in coordinate cartesiane sostituendo $y = a+ib$
\begin{align}
	\phi(y)) &= \phi(a,b) = -(a+ib)^2 -2i(a+ib) -1 = \nonumber\\
	&= -a^2 - 2iab + b^2 - 2ia + 2b -1 =   \nonumber\\
	&= (b^2 -a^2 + 2b -1) -2ia(b + 1)
\end{align}
Da cui abbiamo che
\begin{align}
	u(a,b) &= b^2 -a^2 + 2b -1\\
	v(a,b) &= -2a(b + 1)
\end{align}
Cerchiamo ora i cammini a fase costante passanti per $y_0$. Sostituendo troviamo che
\begin{align}
	&v(0,-1) = -2\cdot 0 \cdot (0 + 1) =0\\
	&a(b + 1) = 0 \to \double{a=0 \quad &\text{asse immaginario}}{b=-1 \quad &\text{asse reale traslato di $-i$}}
\end{align}
Ma quale dei due cammini è quello che serve a noi? Andiamo a sostituire nell'espressione di $u(a,b)$:
\begin{enumerate}
	\item Sostituiamo $a=0$
	\begin{align}
		u(0,b) &= b^2 + 2b-1 \\
		\left. \frac{d u}{d b} \right|_{a=0} &= 2b + 2 \\ 
		\left. \frac{d^2 u}{d b^2} \right|_{a=0} &= 2 \geq 0  
	\end{align}
	Siccome non abbiamo $\ddot u <0$ questo cammino non va bene.
	\item Sostituiamo $b=-1$
	\begin{align}
		u(a,-1) &= 1 -a^2 -2-1 = -a^2 -2 \\
		\left. \frac{d u}{d a} \right|_{b=-1} &= -2a\\ 
		\left. \frac{d^2 u}{d a^2} \right|_{b=-1} &= -2 \leq 0  
	\end{align}
\end{enumerate}

Il cammino giusto è quindi 
\begin{align}
	\gamma^*= \left\{ (a,b) \in \C \taleche (a,b) = (a,-1) \right\}
\end{align}
I cui punti sono parametrizzati come
\begin{align}
	y= a - i \spacer a \in \R
\end{align}
E da cui segue che
\begin{align}
	Re(\phi) &= u(a,b) = -a^2 - 2 \\
	Im (\phi) &=v(a,b) = 0
\end{align}
Andiamo quindi a sostituire nella nostra funzione integrale ed otteniamo
\begin{align}
	F(x) &= \int_\R da \; e^{x[-2-a^2]} \frac{1}{a^2 -2ia -1 + 2} =\nonumber\\
	&= \int_\R da \; e^{x[-2-a^2]} \frac{1}{a^2 -2ia +1} 
\end{align}

Siccome stiamo su sviluppando sul punto di sella $(0,-1)$ il denominatore può essre approssimato a $1$, e abbiamo quindi
\begin{align}
	F(x) &= e^{-2x}\int_\R da \; e^{-xa^2} = e^{-2x} \sqrt{\frac{\pi}{x}}
\end{align}

\newpage

\subsection{Esempio 2}

Calcoliamo i termini Leading e Subleading per lo sviluppo asintotico della seguente funzione integrale
\begin{align}
	F(x) &= \int_{-i\infty}^{+i\infty} dx \; e^{ix(z^2-2z)} \frac{1}{\sqrt{1+z}}\\
	g(z) &=\frac{1}{\sqrt{1+z}}\\
	\phi(z) &= i(z^2-2z)
\end{align}
Andiamo a calcolare le derivate di $\phi(z)$ e a trovare il punto di sella
\begin{align}
	\phi(z) &= i(z^2-2z)\\
	\dot{\phi}(z) &= i(2z-2) \to z_0=1\\
	\ddot{\phi}(z) &= 2i
\end{align}
Passiamo in coordinate cartesiane ponendo $z = x+iy$ e otteniamo
\begin{align}
	z_0 &= x_0 + iy_0 = 1 \to z_0=(1,0)\\
	\phi(x,y) &= i[( x+iy )^2 -2x -2iy] = i( x^2 + 2ixy -y^2  -2x -2iy) = \nonumber\\
	&= i[( x^2 -y^2 -2x ) + 2i (xy -y)]  = \nonumber\\
	&=2y(1-x) + i( x^2 -y^2 -2x )
\end{align}
Da cui quindi otteniamo
\begin{align}
	\phi(x,y) &= u(x,y) + iv(x,y)\\
	u(x,y) &= 2y(1-x) \to u(0,1) = 2\\
	v(x,y) &= x^2 -y^2 -2x \to v(0,1) = -1
\end{align}
Vogliamo quindi trovare i percorsi tali che $Im(\phi(z)) = -1$. Per fare ciò poniamo
\begin{align}
	&x^2 -y^2 -2x = -1\firstpassage
	&x^2 -y^2 -2x +1 =0\nextpassage
	&(x-1)^2 = y^2\nextpassage
	&y=\pm(x-1)
\end{align}
Le nostre curve sono quindi due rette. Cerchiamo ora quale fa al caso nostro
\begin{align}
	y_1=x-1 \to u_1(x) &= -2(1-x)^2 \to \dot{u}_1(x) = -4(1-x)\\
	y_2=1-x \to u_2(x) &= +2(1-x)^2 \to \dot{u}_2(x) = +4(1-x)
\end{align}

Studiando l'andamento delle derivate notiamo come $u_1(x)$ abbia un massimo in $x=1$,e che quindi è la nostra curva d'interesse.

Andiamo ora a parametrizzare. Siccome i punti della nostra curva sono ruotati di $45°$ rispetto all'asse reale, scriviamo
\begin{align}
	&z = 1+ e^{i\frac{\pi}{4}} \tau\firstpassage
	&dz = e^{i\frac{\pi}{4}} d\tau
\end{align}	
Possiamo quindi riscrivere
\begin{align}	
	\phi(\tau) &= i[(1+ e^{i\frac{\pi}{4}} \tau)^2-2(1+ e^{i\frac{\pi}{4}} \tau)] =\nonumber\\
	&= i[ 1 + \cancel{2e^{i\frac{\pi}{4}}\tau} + e^{i\frac{\pi}{2}}\tau^2 - 2 -\cancel{2e^{i\frac{\pi}{4}}\tau} ]=\nonumber\\
	&= i (e^{i\frac{\pi}{2}}\tau^2 -1)=\nonumber\\
	&= i (-i\tau^2 -1) = -\tau^2 -i
\end{align}

\textbf{Nota bene:} abbiamo bisogno del termine subleading, ma questo non compare dalla formula del $d\tau$ che si ferma prima di $\tau^2$. Dobbiamo quindi sviluppare $g(z)$ intorno a $z_0$
\begin{align}
	g(z) = \left. \frac{1}{\sqrt{1+z}} \right|_{z=1 + e^{1\frac{\pi}{2}}} = \frac{1}{\sqrt{2}} \frac{1}{\sqrt{1 + \frac{e^{1\frac{\pi}{2}}}{2}}} \sim 1 - \cancel{\frac{e^{i\frac{\pi}{4}}}{4}\tau} + \frac{3}{8} \frac{e^{i\frac{\pi}{2}}}{4} \tau^2
\end{align}
Possiamo quindi riscrivere la nostra funzione integrale come
\begin{align}
	I(x) &= \int_\R d\tau; \frac{e^{x(-i-\tau^2)}}{\sqrt{2}} \left( 1  + \frac{3}{32} i \tau^2 \right)e^{i\frac{\pi}{4}} = \nonumber \\
	&= \frac{e^{-i\left( x-\frac{\pi}{4} \right)}}{\sqrt{2}}\left[ \int_\R d\tau  \; e^{-x\tau^2}  + \frac{3i}{32} \int_\R d\tau \; e^{-x\tau^2} \tau^2\right] = \nonumber \\
	&= \frac{e^{-i\left( x-\frac{\pi}{4} \right)}}{\sqrt{2}}\left[ \sqrt{\frac{\pi}{x}}   + \frac{3i}{32} \sqrt{\frac{\pi}{x^3}} \right]
\end{align}
